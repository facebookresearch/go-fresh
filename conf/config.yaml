main:
    name: ${now:%Y%m%d-%H%M%S}_${env.id}_${main.suffix}
    suffix:
    logs_dir: /checkpoint/${env:USER}/offline-gcrl/logs/${main.name}  # store all model files
    save_interval: 100
    oracle_reward: false
    run: #dummy variable for several runs

env:
    id: maze_U4rooms
    success_thresh: 0.5
    max_episode_steps: 100
    action_repeat: 1
    random_start_pos: false
    obs:
        type: vec
        state_size:
        vec_size:
        rgb_size:
    action_dim:

exploration_buffer:
    data_dir:
    num_procs: 10

replay_buffer:
    capacity: 100000
    reward_scaling: 0.01

optim:
    num_epochs: 1001

train:
    goal_strat: rb #goal sampling strategy: rb or one_goal

eval:
    num_episodes: 500
    num_procs: 10
    goal_idx:

sac:
    policy:
        type: Gaussian
        hidden_size: 256
        head:
            type: fc
            out_size: 16
            hidden_size: 64
            n_layers: 3
            normalize: true
    
    optim:
        lr: 0.001 
        batch_size: 1024
        num_updates_per_epoch: 1000
        tau: 0.005
        gamma: 0.99
        target_update_interval: 1
        entropy:
            alpha: 0.01
            auto_tuning: false
            lr: 0.0003
        policy:
            lr: ${sac.optim.lr}  #use different LR for the policy

rnet:
    model:
        feat_size: 16
        hidden_size: 64
        comparator: net
        n_layers: 3  # of the feature encoder
        comp_n_layers: 2  # of the net comparator
        remove_velocity: true #remove velocity for maze
        dims_to_keep:
    dataset:
        thresh: 10
        neg_thresh: 0  # sample negative pairs within this distance
        in_traj_ratio: 0.5
        symmetric: true
        valid_ratio: 0.05  # ratio of data to be used as validation
        num_pairs:
            train: 500000  # not the actual data size
            val: 100000  # not the actual data size
    train:
        lr: 0.001
        num_epochs: 10
        batch_size: 512
        num_workers: 32
        weight_decay: 0.00001
    memory:
        thresh: 0
        capacity: 500
        skip: 1
        NN_batch_size: 1
        skip_traj: 0.05 #percentage of trajectories NOT to skip
        directed: false

hydra:
    launcher:
        nodes: 1
        cpus_per_task: 10
        signal_delay_s: 30
        timeout_min: 4230
        gpus_per_node: 1
        tasks_per_node: 1
        partition: learnlab
        name: ${main.name}

    job_logging:
        formatters:
            simple:
                format: '[%(levelname)s] - %(message)s'

    sweep:
        dir: /checkpoint/${env:USER}/offline-gcrl/logs/multirun/${main.name}

defaults:
    - override hydra/launcher: submitit_slurm
